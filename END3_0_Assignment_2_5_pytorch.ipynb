{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END3_0_Assignment_2_5_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftdc2inZn285"
      },
      "source": [
        "# Imports and Data Download :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhYyCI3RmsBB",
        "outputId": "ba2dd9c1-faec-424f-f263-caeadb879ede"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "mnist_trainset = torchvision.datasets.MNIST(\n",
        "                              root='./data', \n",
        "                              train=True, \n",
        "                              download=True, \n",
        "                              transform=transforms.Compose([\n",
        "                                  transforms.ToTensor()\n",
        "                              ])\n",
        "                  )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXpEw-HoQsaJ"
      },
      "source": [
        "# Data Preparation :\n",
        "* This code contains logic to create the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybgUK2Kvb34x"
      },
      "source": [
        "def create_one_hotencoding_inp(x: int):\n",
        "  \"\"\"\n",
        "  This function allows user to convert the input number (between 0 to 9) \n",
        "  in to one hot encoded vector of size 10.\n",
        "  input : x = number between 0-9\n",
        "  output : base_arr = one hot encoded vector with 10 list elements\n",
        "  \"\"\"\n",
        "  assert isinstance(x, int) or isinstance(x, np.int64) or isinstance(x, np.int32), \"input should be of datatype 'int'\"\n",
        "  assert x>=0 and x<=9, \"input should be between 0-9\"\n",
        "  base_arr = np.zeros(10)\n",
        "  base_arr[x] = 1\n",
        "  return base_arr\n",
        "\n",
        "# create_one_hotencoding_inp(\"2\")  # Error checking for string input\n",
        "# create_one_hotencoding_inp(10) # Error checking for number not in range 0-9"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyXZl379E6gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28a9d0f-3c56-4686-9977-d67f09e0c43f"
      },
      "source": [
        "def extract_images_and_labels(num_obs: int, mnist_trainset):\n",
        "  i=0\n",
        "  i_max=int(num_obs)\n",
        "  lst_imgs = []\n",
        "  lst_labels = []\n",
        "  for img, label in mnist_trainset:\n",
        "    lst_imgs.append(img)\n",
        "    lst_labels.append(label)\n",
        "    i += 1\n",
        "    if i==i_max:\n",
        "      break;\n",
        "\n",
        "  # Checking class distribution\n",
        "  df_class_distro = pd.DataFrame(pd.Series(lst_labels).value_counts().sort_index(), columns=['count_labels']).reset_index()\n",
        "  df_class_distro.rename({'index':'class_label'}, axis=1, inplace=True)\n",
        "  print(f\"Printing class distibution below : \\n{df_class_distro}\")\n",
        "  return(lst_imgs, lst_labels)\n",
        "\n",
        "lst_imgs, lst_labels = extract_images_and_labels(30000, mnist_trainset)\n",
        "print(len(lst_imgs))\n",
        "print(len(lst_labels))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing class distibution below : \n",
            "   class_label  count_labels\n",
            "0            0          2961\n",
            "1            1          3423\n",
            "2            2          2948\n",
            "3            3          3073\n",
            "4            4          2926\n",
            "5            5          2709\n",
            "6            6          2975\n",
            "7            7          3107\n",
            "8            8          2875\n",
            "9            9          3003\n",
            "30000\n",
            "30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94e7NAN5RBqX",
        "outputId": "1df42dcf-bc6a-4063-f012-be3a5faa2f87"
      },
      "source": [
        "def prepare_my_dataset(lst_imgs: list, lst_labels: list):\n",
        "  \"\"\"\n",
        "  This function will prepare the dataset as per the below requirement :\n",
        "  Creates the tensor of input images\n",
        "  Creates the random input numbers same as size of input images & creates the one hot encoded vectors of each obs\n",
        "  Creates the tensor of output image labels\n",
        "  Creates the target sum which is sum of input random number and image label\n",
        "  \"\"\"\n",
        "  inp_images = torch.stack(lst_imgs)\n",
        "  out_img_labels = torch.tensor(lst_labels)\n",
        "\n",
        "  i = 0\n",
        "  while i!=10:\n",
        "    inp_rand_np = np.random.randint(0,10,len(out_img_labels))\n",
        "    i = pd.Series(inp_rand_np).nunique()\n",
        "    print(f\"Number of unique values in my random set '{i}'\")\n",
        "\n",
        "  inp_rand = torch.tensor(inp_rand_np)\n",
        "  out_sum = inp_rand + out_img_labels\n",
        "\n",
        "  inp_rand_ohe = torch.tensor([create_one_hotencoding_inp(x) for x in inp_rand_np])\n",
        "  return(inp_images, inp_rand_ohe, out_img_labels, out_sum)\n",
        "\n",
        "inp_images, inp_rand_ohe, out_img_labels, out_sum = prepare_my_dataset(lst_imgs, lst_labels)\n",
        "print(inp_images.shape)\n",
        "print(inp_rand_ohe.shape)\n",
        "print(out_img_labels.shape)\n",
        "print(out_sum.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique values in my random set '10'\n",
            "torch.Size([30000, 1, 28, 28])\n",
            "torch.Size([30000, 10])\n",
            "torch.Size([30000])\n",
            "torch.Size([30000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqXGsxT39_hD",
        "outputId": "026bc1f7-01a3-4f81-a4d2-9cbfa5047d5d"
      },
      "source": [
        "# Assigning all the input tensors to cuda\n",
        "print(\"device before allocating to cuda : \",inp_images.device, inp_rand_ohe.device, out_img_labels.device, out_sum.device)\n",
        "inp_images, inp_rand_ohe, out_img_labels, out_sum = inp_images.cuda(), inp_rand_ohe.cuda(), out_img_labels.cuda(), out_sum.cuda()\n",
        "print(\"device after allocating to cuda : \",inp_images.device, inp_rand_ohe.device, out_img_labels.device, out_sum.device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device before allocating to cuda :  cpu cpu cpu cpu\n",
            "device after allocating to cuda :  cuda:0 cuda:0 cuda:0 cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QVNfkFXFgFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c883fbd6-61cf-4442-f022-fb4906037017"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Creating the Custom dataset using previously created data so that we can use this dataset object to create batches later\n",
        "class CustomMnistDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = []\n",
        "    for i in range(0,len(out_sum)):\n",
        "      self.data.append([inp_images[i], inp_rand_ohe[i], out_img_labels[i], out_sum[i]])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myDataset = CustomMnistDataset()\n",
        "len(myDataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXKK0eARSRR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a9c8e9-da11-4afb-f77a-9d6d9c03c654"
      },
      "source": [
        "# creating train_loader so that we can load data in batches while training\n",
        "train_loader = torch.utils.data.DataLoader(myDataset\n",
        "    ,batch_size=32\n",
        "    ,shuffle=True\n",
        ")\n",
        "\n",
        "len(train_loader)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "938"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i376ED-SSRQH",
        "outputId": "855fb232-e3ad-431c-fefb-a34427b95fd2"
      },
      "source": [
        "# Printing the size of first 3 batches\n",
        "i=0\n",
        "for tr in train_loader:\n",
        "  print(tr[0].shape, tr[1].shape, tr[2].shape, tr[3].shape)\n",
        "  i+=1\n",
        "  if i==3:\n",
        "    break;"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28]) torch.Size([32, 10]) torch.Size([32]) torch.Size([32])\n",
            "torch.Size([32, 1, 28, 28]) torch.Size([32, 10]) torch.Size([32]) torch.Size([32])\n",
            "torch.Size([32, 1, 28, 28]) torch.Size([32, 10]) torch.Size([32]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yli7pGpvY5s"
      },
      "source": [
        "# Model Building :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL3NOIEInyc5"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K5NLANk114C"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #28 - > 24 - > 12 -> 8 -> 4\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=(12 * 4 * 4)+10, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out1 = nn.Linear(in_features=60, out_features=10)\n",
        "    self.out2 = nn.Linear(in_features=60, out_features=19)\n",
        "  \n",
        "  def forward(self, t1, t2):\n",
        "    # input layer\n",
        "    x, y = t1, t2\n",
        "\n",
        "    # conv1 layer\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 28 | 24 | 12\n",
        "\n",
        "    # conv2 layer\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 12 | 8 | 4 >> 12x4x4\n",
        "\n",
        "    # reshapre\n",
        "    x = x.reshape(-1, 12 * 4 * 4)\n",
        "    z = torch.cat((x,y.reshape(-1,10)), dim=1)\n",
        "    \n",
        "    # fc1 layer\n",
        "    z = self.fc1(z)\n",
        "    z = F.relu(z)\n",
        "\n",
        "    # fc2 layer\n",
        "    z = self.fc2(z)\n",
        "    z = F.relu(z)\n",
        "\n",
        "    # output layer 1\n",
        "    o1 = self.out1(z)\n",
        "    o1 = F.softmax(o1, dim=1)\n",
        "\n",
        "    # output layer 2\n",
        "    o2 = self.out2(z)\n",
        "    o2 = F.softmax(o2, dim=1)\n",
        "    return o1, o2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INpFWsIg47BJ",
        "outputId": "23ecc134-851d-479b-a4db-fbf5826b7240"
      },
      "source": [
        "network = Network()\n",
        "\n",
        "print(network)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=202, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (out1): Linear(in_features=60, out_features=10, bias=True)\n",
            "  (out2): Linear(in_features=60, out_features=19, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZyLgfAK-mPi"
      },
      "source": [
        "# Assigning my network parameters to cuda as well\n",
        "network = network.cuda()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcZHjEdl5OVo",
        "outputId": "6ae31a59-28bf-4bc5-f3c9-31b4724b78b1"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "torch.set_grad_enabled(True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa979ed8dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iev6EmMhd2Pm"
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38jIyDf-cZ3T",
        "outputId": "504dff09-bedf-4140-aca9-f5fa54f44dff"
      },
      "source": [
        "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct_labels = 0\n",
        "    total_correct_sum = 0\n",
        "\n",
        "    for batch in train_loader: # Get Batch\n",
        "        i_images, i_rand, o_labels, o_sum = batch \n",
        "\n",
        "        preds_labels, preds_sum = network(i_images, i_rand.float()) # Pass Batch\n",
        "        loss1 = F.cross_entropy(preds_labels, o_labels) # Calculate Loss\n",
        "        loss2 = F.cross_entropy(preds_sum, o_sum) # Calculate Loss\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct_labels += get_num_correct(preds_labels, o_labels)\n",
        "        total_correct_sum += get_num_correct(preds_sum, o_sum)\n",
        "\n",
        "    print(\n",
        "        \"epoch\", epoch, \n",
        "        \" | total_correct_labels:\", total_correct_labels,\n",
        "        \"/\",round((total_correct_labels/len(inp_rand_ohe))*100,2),\"%\",\n",
        "        \" | total_correct_sum:\", total_correct_sum, \n",
        "        \"/\",round((total_correct_sum/len(inp_rand_ohe))*100,2),\"%\",\n",
        "        \" | loss:\", total_loss\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | total_correct_labels: 22683 / 75.61 %  | total_correct_sum: 2933 / 9.78 %  | loss: 4343.642276287079\n",
            "epoch 1  | total_correct_labels: 28595 / 95.32 %  | total_correct_sum: 3527 / 11.76 %  | loss: 4138.888205051422\n",
            "epoch 2  | total_correct_labels: 28922 / 96.41 %  | total_correct_sum: 6319 / 21.06 %  | loss: 4059.9134788513184\n",
            "epoch 3  | total_correct_labels: 29047 / 96.82 %  | total_correct_sum: 11405 / 38.02 %  | loss: 3906.726266145706\n",
            "epoch 4  | total_correct_labels: 29234 / 97.45 %  | total_correct_sum: 13261 / 44.2 %  | loss: 3830.9711167812347\n",
            "epoch 5  | total_correct_labels: 29347 / 97.82 %  | total_correct_sum: 13721 / 45.74 %  | loss: 3808.318681716919\n",
            "epoch 6  | total_correct_labels: 29407 / 98.02 %  | total_correct_sum: 13942 / 46.47 %  | loss: 3796.4209303855896\n",
            "epoch 7  | total_correct_labels: 29512 / 98.37 %  | total_correct_sum: 13995 / 46.65 %  | loss: 3790.6346876621246\n",
            "epoch 8  | total_correct_labels: 29566 / 98.55 %  | total_correct_sum: 14288 / 47.63 %  | loss: 3779.3786714076996\n",
            "epoch 9  | total_correct_labels: 29631 / 98.77 %  | total_correct_sum: 14480 / 48.27 %  | loss: 3770.7530987262726\n",
            "epoch 10  | total_correct_labels: 29646 / 98.82 %  | total_correct_sum: 14657 / 48.86 %  | loss: 3763.8622982501984\n",
            "epoch 11  | total_correct_labels: 29679 / 98.93 %  | total_correct_sum: 15285 / 50.95 %  | loss: 3743.472644329071\n",
            "epoch 12  | total_correct_labels: 29695 / 98.98 %  | total_correct_sum: 15848 / 52.83 %  | loss: 3725.0967712402344\n",
            "epoch 13  | total_correct_labels: 29731 / 99.1 %  | total_correct_sum: 15946 / 53.15 %  | loss: 3719.758322954178\n",
            "epoch 14  | total_correct_labels: 29731 / 99.1 %  | total_correct_sum: 15969 / 53.23 %  | loss: 3719.1138627529144\n",
            "epoch 15  | total_correct_labels: 29770 / 99.23 %  | total_correct_sum: 16286 / 54.29 %  | loss: 3707.7213184833527\n",
            "epoch 16  | total_correct_labels: 29781 / 99.27 %  | total_correct_sum: 16298 / 54.33 %  | loss: 3706.1151263713837\n",
            "epoch 17  | total_correct_labels: 29790 / 99.3 %  | total_correct_sum: 16426 / 54.75 %  | loss: 3701.8615202903748\n",
            "epoch 18  | total_correct_labels: 29809 / 99.36 %  | total_correct_sum: 17320 / 57.73 %  | loss: 3674.911979675293\n",
            "epoch 19  | total_correct_labels: 29830 / 99.43 %  | total_correct_sum: 18564 / 61.88 %  | loss: 3635.363618373871\n",
            "epoch 20  | total_correct_labels: 29847 / 99.49 %  | total_correct_sum: 19013 / 63.38 %  | loss: 3620.6107835769653\n",
            "epoch 21  | total_correct_labels: 29824 / 99.41 %  | total_correct_sum: 19498 / 64.99 %  | loss: 3606.420508146286\n",
            "epoch 22  | total_correct_labels: 29846 / 99.49 %  | total_correct_sum: 20429 / 68.1 %  | loss: 3577.560647010803\n",
            "epoch 23  | total_correct_labels: 29837 / 99.46 %  | total_correct_sum: 20879 / 69.6 %  | loss: 3563.3039407730103\n",
            "epoch 24  | total_correct_labels: 29874 / 99.58 %  | total_correct_sum: 21014 / 70.05 %  | loss: 3557.24804520607\n",
            "epoch 25  | total_correct_labels: 29860 / 99.53 %  | total_correct_sum: 21124 / 70.41 %  | loss: 3554.330409526825\n",
            "epoch 26  | total_correct_labels: 29859 / 99.53 %  | total_correct_sum: 21307 / 71.02 %  | loss: 3548.718550682068\n",
            "epoch 27  | total_correct_labels: 29875 / 99.58 %  | total_correct_sum: 21313 / 71.04 %  | loss: 3547.1447200775146\n",
            "epoch 28  | total_correct_labels: 29854 / 99.51 %  | total_correct_sum: 21321 / 71.07 %  | loss: 3547.7654523849487\n",
            "epoch 29  | total_correct_labels: 29879 / 99.6 %  | total_correct_sum: 21328 / 71.09 %  | loss: 3546.58425450325\n",
            "epoch 30  | total_correct_labels: 29880 / 99.6 %  | total_correct_sum: 21335 / 71.12 %  | loss: 3546.0490119457245\n",
            "epoch 31  | total_correct_labels: 29893 / 99.64 %  | total_correct_sum: 21332 / 71.11 %  | loss: 3545.8654403686523\n",
            "epoch 32  | total_correct_labels: 29892 / 99.64 %  | total_correct_sum: 21431 / 71.44 %  | loss: 3542.823474884033\n",
            "epoch 33  | total_correct_labels: 29895 / 99.65 %  | total_correct_sum: 21645 / 72.15 %  | loss: 3536.0319678783417\n",
            "epoch 34  | total_correct_labels: 29906 / 99.69 %  | total_correct_sum: 21699 / 72.33 %  | loss: 3533.946453809738\n",
            "epoch 35  | total_correct_labels: 29905 / 99.68 %  | total_correct_sum: 21881 / 72.94 %  | loss: 3528.1153569221497\n",
            "epoch 36  | total_correct_labels: 29902 / 99.67 %  | total_correct_sum: 21888 / 72.96 %  | loss: 3527.618245601654\n",
            "epoch 37  | total_correct_labels: 29889 / 99.63 %  | total_correct_sum: 22297 / 74.32 %  | loss: 3516.7077593803406\n",
            "epoch 38  | total_correct_labels: 29919 / 99.73 %  | total_correct_sum: 22501 / 75.0 %  | loss: 3508.8884127140045\n",
            "epoch 39  | total_correct_labels: 29894 / 99.65 %  | total_correct_sum: 22558 / 75.19 %  | loss: 3507.9802565574646\n",
            "epoch 40  | total_correct_labels: 29915 / 99.72 %  | total_correct_sum: 22803 / 76.01 %  | loss: 3499.64236164093\n",
            "epoch 41  | total_correct_labels: 29895 / 99.65 %  | total_correct_sum: 23004 / 76.68 %  | loss: 3494.2036731243134\n",
            "epoch 42  | total_correct_labels: 29890 / 99.63 %  | total_correct_sum: 23006 / 76.69 %  | loss: 3494.338627576828\n",
            "epoch 43  | total_correct_labels: 29928 / 99.76 %  | total_correct_sum: 23020 / 76.73 %  | loss: 3492.0550870895386\n",
            "epoch 44  | total_correct_labels: 29922 / 99.74 %  | total_correct_sum: 23023 / 76.74 %  | loss: 3492.1130187511444\n",
            "epoch 45  | total_correct_labels: 29943 / 99.81 %  | total_correct_sum: 23032 / 76.77 %  | loss: 3490.837609052658\n",
            "epoch 46  | total_correct_labels: 29932 / 99.77 %  | total_correct_sum: 23035 / 76.78 %  | loss: 3491.6595385074615\n",
            "epoch 47  | total_correct_labels: 29894 / 99.65 %  | total_correct_sum: 23304 / 77.68 %  | loss: 3485.0767912864685\n",
            "epoch 48  | total_correct_labels: 29910 / 99.7 %  | total_correct_sum: 23316 / 77.72 %  | loss: 3483.709615945816\n",
            "epoch 49  | total_correct_labels: 29943 / 99.81 %  | total_correct_sum: 23356 / 77.85 %  | loss: 3481.0380566120148\n",
            "epoch 50  | total_correct_labels: 29921 / 99.74 %  | total_correct_sum: 23850 / 79.5 %  | loss: 3467.199858903885\n",
            "epoch 51  | total_correct_labels: 29931 / 99.77 %  | total_correct_sum: 23920 / 79.73 %  | loss: 3464.846992969513\n",
            "epoch 52  | total_correct_labels: 29935 / 99.78 %  | total_correct_sum: 23931 / 79.77 %  | loss: 3464.129353761673\n",
            "epoch 53  | total_correct_labels: 29945 / 99.82 %  | total_correct_sum: 23939 / 79.8 %  | loss: 3463.169775247574\n",
            "epoch 54  | total_correct_labels: 29913 / 99.71 %  | total_correct_sum: 23905 / 79.68 %  | loss: 3465.13681101799\n",
            "epoch 55  | total_correct_labels: 29950 / 99.83 %  | total_correct_sum: 23937 / 79.79 %  | loss: 3462.8963096141815\n",
            "epoch 56  | total_correct_labels: 29941 / 99.8 %  | total_correct_sum: 23935 / 79.78 %  | loss: 3463.0139067173004\n",
            "epoch 57  | total_correct_labels: 29931 / 99.77 %  | total_correct_sum: 23929 / 79.76 %  | loss: 3463.7659242153168\n",
            "epoch 58  | total_correct_labels: 29930 / 99.77 %  | total_correct_sum: 23925 / 79.75 %  | loss: 3464.378406047821\n",
            "epoch 59  | total_correct_labels: 29950 / 99.83 %  | total_correct_sum: 23937 / 79.79 %  | loss: 3462.9724345207214\n",
            "epoch 60  | total_correct_labels: 29929 / 99.76 %  | total_correct_sum: 23927 / 79.76 %  | loss: 3464.364182472229\n",
            "epoch 61  | total_correct_labels: 29931 / 99.77 %  | total_correct_sum: 23925 / 79.75 %  | loss: 3463.9658057689667\n",
            "epoch 62  | total_correct_labels: 29926 / 99.75 %  | total_correct_sum: 23933 / 79.78 %  | loss: 3463.8903424739838\n",
            "epoch 63  | total_correct_labels: 29936 / 99.79 %  | total_correct_sum: 23933 / 79.78 %  | loss: 3463.4863290786743\n",
            "epoch 64  | total_correct_labels: 29940 / 99.8 %  | total_correct_sum: 23935 / 79.78 %  | loss: 3463.375376701355\n",
            "epoch 65  | total_correct_labels: 29940 / 99.8 %  | total_correct_sum: 23927 / 79.76 %  | loss: 3463.5391228199005\n",
            "epoch 66  | total_correct_labels: 29962 / 99.87 %  | total_correct_sum: 23946 / 79.82 %  | loss: 3461.8651583194733\n",
            "epoch 67  | total_correct_labels: 29949 / 99.83 %  | total_correct_sum: 24184 / 80.61 %  | loss: 3455.3110880851746\n",
            "epoch 68  | total_correct_labels: 29932 / 99.77 %  | total_correct_sum: 24275 / 80.92 %  | loss: 3453.6045219898224\n",
            "epoch 69  | total_correct_labels: 29949 / 99.83 %  | total_correct_sum: 24287 / 80.96 %  | loss: 3452.2463970184326\n",
            "epoch 70  | total_correct_labels: 29936 / 99.79 %  | total_correct_sum: 24277 / 80.92 %  | loss: 3452.7978723049164\n",
            "epoch 71  | total_correct_labels: 29941 / 99.8 %  | total_correct_sum: 24274 / 80.91 %  | loss: 3453.120053291321\n",
            "epoch 72  | total_correct_labels: 29939 / 99.8 %  | total_correct_sum: 24273 / 80.91 %  | loss: 3452.9729738235474\n",
            "epoch 73  | total_correct_labels: 29954 / 99.85 %  | total_correct_sum: 24289 / 80.96 %  | loss: 3451.818320274353\n",
            "epoch 74  | total_correct_labels: 29950 / 99.83 %  | total_correct_sum: 24288 / 80.96 %  | loss: 3451.8126657009125\n",
            "epoch 75  | total_correct_labels: 29940 / 99.8 %  | total_correct_sum: 24277 / 80.92 %  | loss: 3452.7291254997253\n",
            "epoch 76  | total_correct_labels: 29947 / 99.82 %  | total_correct_sum: 24288 / 80.96 %  | loss: 3452.17068195343\n",
            "epoch 77  | total_correct_labels: 29968 / 99.89 %  | total_correct_sum: 24297 / 80.99 %  | loss: 3450.699605703354\n",
            "epoch 78  | total_correct_labels: 29969 / 99.9 %  | total_correct_sum: 24297 / 80.99 %  | loss: 3450.2685894966125\n",
            "epoch 79  | total_correct_labels: 29902 / 99.67 %  | total_correct_sum: 24260 / 80.87 %  | loss: 3454.8728992938995\n",
            "epoch 80  | total_correct_labels: 29931 / 99.77 %  | total_correct_sum: 24284 / 80.95 %  | loss: 3452.8211476802826\n",
            "epoch 81  | total_correct_labels: 29950 / 99.83 %  | total_correct_sum: 24288 / 80.96 %  | loss: 3452.0823731422424\n",
            "epoch 82  | total_correct_labels: 29959 / 99.86 %  | total_correct_sum: 24288 / 80.96 %  | loss: 3451.7018542289734\n",
            "epoch 83  | total_correct_labels: 29952 / 99.84 %  | total_correct_sum: 24294 / 80.98 %  | loss: 3451.3384234905243\n",
            "epoch 84  | total_correct_labels: 29951 / 99.84 %  | total_correct_sum: 24290 / 80.97 %  | loss: 3451.5886418819427\n",
            "epoch 85  | total_correct_labels: 29956 / 99.85 %  | total_correct_sum: 24284 / 80.95 %  | loss: 3451.7453439235687\n",
            "epoch 86  | total_correct_labels: 29931 / 99.77 %  | total_correct_sum: 24278 / 80.93 %  | loss: 3452.929561138153\n",
            "epoch 87  | total_correct_labels: 29958 / 99.86 %  | total_correct_sum: 24283 / 80.94 %  | loss: 3451.568645477295\n",
            "epoch 88  | total_correct_labels: 29967 / 99.89 %  | total_correct_sum: 24297 / 80.99 %  | loss: 3450.4921522140503\n",
            "epoch 89  | total_correct_labels: 29925 / 99.75 %  | total_correct_sum: 24274 / 80.91 %  | loss: 3453.460672855377\n",
            "epoch 90  | total_correct_labels: 29954 / 99.85 %  | total_correct_sum: 24292 / 80.97 %  | loss: 3451.5346150398254\n",
            "epoch 91  | total_correct_labels: 29933 / 99.78 %  | total_correct_sum: 24312 / 81.04 %  | loss: 3451.56968998909\n",
            "epoch 92  | total_correct_labels: 29946 / 99.82 %  | total_correct_sum: 24594 / 81.98 %  | loss: 3442.7339725494385\n",
            "epoch 93  | total_correct_labels: 29944 / 99.81 %  | total_correct_sum: 24598 / 81.99 %  | loss: 3442.9750261306763\n",
            "epoch 94  | total_correct_labels: 29967 / 99.89 %  | total_correct_sum: 24610 / 82.03 %  | loss: 3441.266167640686\n",
            "epoch 95  | total_correct_labels: 29958 / 99.86 %  | total_correct_sum: 24607 / 82.02 %  | loss: 3441.528431415558\n",
            "epoch 96  | total_correct_labels: 29941 / 99.8 %  | total_correct_sum: 24587 / 81.96 %  | loss: 3442.9206795692444\n",
            "epoch 97  | total_correct_labels: 29948 / 99.83 %  | total_correct_sum: 24603 / 82.01 %  | loss: 3442.327206134796\n",
            "epoch 98  | total_correct_labels: 29956 / 99.85 %  | total_correct_sum: 24596 / 81.99 %  | loss: 3442.1709427833557\n",
            "epoch 99  | total_correct_labels: 29971 / 99.9 %  | total_correct_sum: 24609 / 82.03 %  | loss: 3440.953696012497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsbcnqw1CQki"
      },
      "source": [
        "# Inference :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be-ygBp9Iyyi"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "bHVpm15DCAto",
        "outputId": "7ea6806a-8afc-4de8-a827-7fcdc478eb38"
      },
      "source": [
        "random_index = np.random.randint(100,inp_images.shape[0], 1)[0]\n",
        "print(f\"Index is : '{random_index}'\")\n",
        "inp_rnd_num_inf = np.random.randint(0,9,1)[0]\n",
        "print(f\"Input Number is : '{inp_rnd_num_inf}'\")\n",
        "\n",
        "inp_rnd_num_inf_ohe = create_one_hotencoding_inp(inp_rnd_num_inf).reshape(1,10)\n",
        "inp_rnd_num_inf_ohe = torch.tensor(inp_rnd_num_inf_ohe).cuda()\n",
        "print(f\"Shape of my inp rand number : {inp_rnd_num_inf_ohe.shape}\")\n",
        "inp_img_inf = inp_images[random_index].reshape(1,1,28,28)\n",
        "print(f\"Shape of my input image : {inp_img_inf.shape}\")\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "image = inp_img_inf.cpu().detach()\n",
        "label = out_img_labels[random_index]\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "print('Actual image label is :', label.cpu().detach().numpy())\n",
        "\n",
        "pred_img_label, pred_sum_label = network(inp_img_inf, inp_rnd_num_inf_ohe.float())\n",
        "print(f\"Actual input random number is : {inp_rnd_num_inf}\")\n",
        "print(f\"Predicted image label is : {pred_img_label.argmax().cpu().detach().numpy()}\")\n",
        "print(f\"Predicted sum label is : {pred_sum_label.argmax().cpu().detach().numpy()}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index is : '9543'\n",
            "Input Number is : '5'\n",
            "Shape of my inp rand number : torch.Size([1, 10])\n",
            "Shape of my input image : torch.Size([1, 1, 28, 28])\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Actual image label is : 8\n",
            "Actual input random number is : 5\n",
            "Predicted image label is : 8\n",
            "Predicted sum label is : 13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "O6LClPEFF9-d",
        "outputId": "ec63b1a7-9778-4c9b-f7e8-74b7a48bdb6f"
      },
      "source": [
        "random_index = np.random.randint(100,inp_images.shape[0], 1)[0]\n",
        "print(f\"Index is : '{random_index}'\")\n",
        "inp_rnd_num_inf = np.random.randint(0,9,1)[0]\n",
        "print(f\"Input Number is : '{inp_rnd_num_inf}'\")\n",
        "\n",
        "inp_rnd_num_inf_ohe = create_one_hotencoding_inp(inp_rnd_num_inf).reshape(1,10)\n",
        "inp_rnd_num_inf_ohe = torch.tensor(inp_rnd_num_inf_ohe).cuda()\n",
        "print(f\"Shape of my inp rand number : {inp_rnd_num_inf_ohe.shape}\")\n",
        "inp_img_inf = inp_images[random_index].reshape(1,1,28,28)\n",
        "print(f\"Shape of my input image : {inp_img_inf.shape}\")\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "image = inp_img_inf.cpu().detach()\n",
        "label = out_img_labels[random_index]\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "print('Actual image label is :', label.cpu().detach().numpy())\n",
        "\n",
        "pred_img_label, pred_sum_label = network(inp_img_inf, inp_rnd_num_inf_ohe.float())\n",
        "print(f\"Actual input random number is : {inp_rnd_num_inf}\")\n",
        "print(f\"Predicted image label is : {pred_img_label.argmax().cpu().detach().numpy()}\")\n",
        "print(f\"Predicted sum label is : {pred_sum_label.argmax().cpu().detach().numpy()}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index is : '10394'\n",
            "Input Number is : '5'\n",
            "Shape of my inp rand number : torch.Size([1, 10])\n",
            "Shape of my input image : torch.Size([1, 1, 28, 28])\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Actual image label is : 7\n",
            "Actual input random number is : 5\n",
            "Predicted image label is : 7\n",
            "Predicted sum label is : 12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "_3mWKdUOKEKG",
        "outputId": "0f952fa1-9d78-4145-ee60-c936909a7b29"
      },
      "source": [
        "random_index = np.random.randint(100,inp_images.shape[0], 1)[0]\n",
        "print(f\"Index is : '{random_index}'\")\n",
        "inp_rnd_num_inf = np.random.randint(0,9,1)[0]\n",
        "print(f\"Input Number is : '{inp_rnd_num_inf}'\")\n",
        "\n",
        "inp_rnd_num_inf_ohe = create_one_hotencoding_inp(inp_rnd_num_inf).reshape(1,10)\n",
        "inp_rnd_num_inf_ohe = torch.tensor(inp_rnd_num_inf_ohe).cuda()\n",
        "print(f\"Shape of my inp rand number : {inp_rnd_num_inf_ohe.shape}\")\n",
        "inp_img_inf = inp_images[random_index].reshape(1,1,28,28)\n",
        "print(f\"Shape of my input image : {inp_img_inf.shape}\")\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "image = inp_img_inf.cpu().detach()\n",
        "label = out_img_labels[random_index]\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "print('Actual image label is :', label.cpu().detach().numpy())\n",
        "\n",
        "pred_img_label, pred_sum_label = network(inp_img_inf, inp_rnd_num_inf_ohe.float())\n",
        "print(f\"Actual input random number is : {inp_rnd_num_inf}\")\n",
        "print(f\"Predicted image label is : {pred_img_label.argmax().cpu().detach().numpy()}\")\n",
        "print(f\"Predicted sum label is : {pred_sum_label.argmax().cpu().detach().numpy()}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index is : '10854'\n",
            "Input Number is : '3'\n",
            "Shape of my inp rand number : torch.Size([1, 10])\n",
            "Shape of my input image : torch.Size([1, 1, 28, 28])\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Actual image label is : 4\n",
            "Actual input random number is : 3\n",
            "Predicted image label is : 4\n",
            "Predicted sum label is : 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "sRPdPmVyNcKu",
        "outputId": "168fd9d4-be4b-4214-8cf2-2c461f637732"
      },
      "source": [
        "random_index = np.random.randint(100,inp_images.shape[0], 1)[0]\n",
        "print(f\"Index is : '{random_index}'\")\n",
        "inp_rnd_num_inf = np.random.randint(0,9,1)[0]\n",
        "print(f\"Input Number is : '{inp_rnd_num_inf}'\")\n",
        "\n",
        "inp_rnd_num_inf_ohe = create_one_hotencoding_inp(inp_rnd_num_inf).reshape(1,10)\n",
        "inp_rnd_num_inf_ohe = torch.tensor(inp_rnd_num_inf_ohe).cuda()\n",
        "print(f\"Shape of my inp rand number : {inp_rnd_num_inf_ohe.shape}\")\n",
        "inp_img_inf = inp_images[random_index].reshape(1,1,28,28)\n",
        "print(f\"Shape of my input image : {inp_img_inf.shape}\")\n",
        "\n",
        "print(\"\\n\\n--------------------------------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "image = inp_img_inf.cpu().detach()\n",
        "label = out_img_labels[random_index]\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "print('Actual image label is :', label.cpu().detach().numpy())\n",
        "\n",
        "pred_img_label, pred_sum_label = network(inp_img_inf, inp_rnd_num_inf_ohe.float())\n",
        "print(f\"Actual input random number is : {inp_rnd_num_inf}\")\n",
        "print(f\"Predicted image label is : {pred_img_label.argmax().cpu().detach().numpy()}\")\n",
        "print(f\"Predicted sum label is : {pred_sum_label.argmax().cpu().detach().numpy()}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index is : '15331'\n",
            "Input Number is : '3'\n",
            "Shape of my inp rand number : torch.Size([1, 10])\n",
            "Shape of my input image : torch.Size([1, 1, 28, 28])\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Actual image label is : 7\n",
            "Actual input random number is : 3\n",
            "Predicted image label is : 7\n",
            "Predicted sum label is : 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}